---
layout: 2021/egsr-default
title: Program
year: 2021
---

## Keynotes

### [Roland Fleming](https://www.allpsych.uni-giessen.de/roland/) - Learning to See Stuff

#### Abstract

Humans are very good at visually recognizing materials and inferring their properties. Without touching surfaces, we can usually tell what they would feel like, and we enjoy vivid visual intuitions about how they typically behave. This is impressive because the retinal image that the visual system receives as input is the result of complex interactions between many physical processes. Somehow the brain has to disentangle these different factors. And yet, we can be exquisitely sensitive to small deviations from physical accuracy in the appearance of behaviourally important materials, like skin. Materials therefore pose many fascinating questions for researchers in computer graphics, industrial design, machine vision and neuroscience. What is ‘material appearance’, and how do we measure it and model it? How are material properties estimated and represented? Discussing these questions causes us to scrutinize the basic assumptions of ‘inverse optics’ that prevail in theories of human vision, and leads us to suggest that unsupervised learning may explain aspects of how the brain infers and represents material properties.  Consistent with this idea, I will present some recent work in which we show that an unsupervised network trained on images of surfaces spontaneously learns to disentangle reflectance, lighting and shape.  More importantly, we find that the network not only predicts the broad successes of human gloss perception, but also the specific pattern of errors that humans exhibit on an image-by-image basis.  We think this has important implications for thinking about vision more broadly.


#### Bio

<a href="https://www.allpsych.uni-giessen.de/roland/">
<img src="{{site.url}}/img/2021/fleming_roland.png" style="float:left; margin-right: 10px" width="150" />
</a>

Roland Fleming is an interdisciplinary researcher specializing in the visual perception of materials, illumination and 3D shape. He did his undergraduate degree in Psychology, Philosophy and Physiology at Oxford University, graduating with First Class Honours in 1999, and completed his PhD in the Department of Brain and Cognitive Sciences at MIT in 2004. He then served as a project leader at the Max Planck Institute for Biological Cybernetics in Tübingen. In 2010 he joined Giessen University as a junior professor. Since 2016, has been the Kurt Koffka Professor of Experimental Psychology.

His research combines psychophysics, neural modelling, computer graphics and image analysis to understand how the brain estimates the physical properties of objects. He has conducted a wide variety of studies on the perception of material properties such as glossiness, translucency, and viscosity and has applied insights from this work to the development of computer graphics algorithms for simulating material appearances. Roland Fleming has served as joint Editor-In-Chief of ACM Transactions on Applied Perception, an interdisciplinary journal dedicated to using perception to advance computer graphics and other fields. In 2012 he was awarded the Faculty Research Prize from the University of Giessen and in 2013 he was awarded the Young Investigator Award by the Vision Sciences Society. In 2016 was awarded an ERC Consolidator Award for the project "SHAPE: On the perception of growth, form and process".


### [Jon Barron](https://jonbarron.info/) - Neural Radiance Fields

#### Abstract

Neural Radiance Fields (Mildenhall, Srinivasan, Tancik, et al., ECCV 2020) are an effective and simple technique for synthesizing photorealistic novel views of complex scenes. NeRF works by optimizing an underlying continuous volumetric radiance field, parameterized by a (non-convolutional) neural network, such that the geometry and appearance of the scene are encoded in the weights of that network. After reviewing NeRF, we will discuss two follow-up works to NeRF that attempt to address its shortcomings and expand is capabilities: 1) a variant of NeRF that uses prefiltering to address issues NeRF has with regard to aliasing and scale, and 2) an extension of NeRF that trains auxiliary neural networks to approximate otherwise-intractable integrals in the rendering equation to enable relighting and material editing.

#### Bio

<a href="https://jonbarron.info/">
<img src="{{site.url}}/img/2021/JonBarron.jpg" style="float:left; margin-right: 10px" width="150" />
</a>

Jon Barron is a staff research scientist at Google, where he works on
computer vision and machine learning. He received a PhD in Computer Science
from the University of California, Berkeley in 2013, where he was advised by
Jitendra Malik, and he received a Honours BSc in Computer Science from the
University of Toronto in 2007. He received a National Science Foundation
Graduate Research Fellowship in 2009, the C.V. Ramamoorthy Distinguished
Research Award in 2013, the PAMI Young Researcher Award in 2020, and the
ECCV Best Paper Honorable Mention in both 2016 and 2020.